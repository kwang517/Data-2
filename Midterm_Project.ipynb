{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwang517/Data-2/blob/MyApp/Midterm_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk8276jzTjNP",
        "outputId": "76830317-87d9-470c-f6c1-74c499d2df26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.148.143.105"
          ]
        }
      ],
      "source": [
        "!curl ipecho.net/plain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt07LxcsTmC3",
        "outputId": "3eaf3990-19cb-453b-e032-585480ef6dea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting install\n",
            "  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (9.0.0)\n",
            "Installing collected packages: install\n",
            "Successfully installed install-1.3.5\n",
            "Collecting codecarbon\n",
            "  Downloading codecarbon-2.3.4-py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting arrow (from codecarbon)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from codecarbon) (1.5.3)\n",
            "Collecting pynvml (from codecarbon)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from codecarbon) (2.31.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from codecarbon) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from codecarbon) (9.0.0)\n",
            "Collecting rapidfuzz (from codecarbon)\n",
            "  Downloading rapidfuzz-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from codecarbon) (8.1.7)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from codecarbon) (0.20.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow->codecarbon) (2.8.2)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow->codecarbon)\n",
            "  Downloading types_python_dateutil-2.8.19.20240106-py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->codecarbon) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->codecarbon) (1.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->codecarbon) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.0->arrow->codecarbon) (1.16.0)\n",
            "Installing collected packages: types-python-dateutil, rapidfuzz, pynvml, arrow, codecarbon\n",
            "Successfully installed arrow-1.3.0 codecarbon-2.3.4 pynvml-11.5.0 rapidfuzz-3.6.1 types-python-dateutil-2.8.19.20240106\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit --quiet\n",
        "!pip install pyngrok --quiet\n",
        "!pip install hvplot --quiet\n",
        "!pip install install psutil py-cpuinfo\n",
        "!pip install codecarbon\n",
        "!pip freeze > requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoDduiwfQtr-",
        "outputId": "f72c00ff-9d00-4ec4-ea3b-56e940fdb81c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import time\n",
        "\n",
        "app_mode = st.sidebar.selectbox('Selectpage:',['01 Introduction','02 Visualization', '03 Prediction'])\n",
        "if app_mode == '01 Introduction':\n",
        "  image_movie = Image.open('movies.jpg')\n",
        "  st.image(image_movie, width=700)\n",
        "\n",
        "  st.title(\"A quantitative observation: What leads to a movie's global success?\")\n",
        "\n",
        "  st.sidebar.header(\"Dashboard\")\n",
        "  st.sidebar.markdown(\"---\")\n",
        "  app_mode = st.sidebar.selectbox('Select Page',['Introduction'])\n",
        "\n",
        "  st.markdown(\"##### Key Objectives\")\n",
        "  st.markdown(\"We aim to investigate the relationship between different factors of movie performance and how it contributes to their profitability as measured by their worldwide gross\")\n",
        "  st.markdown(\"Our data explores the world's top 500 movies by production budget, and these production budgets are not inflation adjusted\")\n",
        "  st.markdown(\"The costs and grosses are measured in USD.\")\n",
        "\n",
        "  df = pd.read_csv(\"top-500-movies.csv\")\n",
        "\n",
        "  head = st.radio('View the top 10 movies by production expenses or View the last 10 movies by production expenses', ('Top 10', 'Last 10'))\n",
        "  if head == 'Top 10':\n",
        "    st.dataframe(df.head(10))\n",
        "  else:\n",
        "    st.dataframe(df.tail(10))\n",
        "\n",
        "  st.markdown(\"##### Key Variables\")\n",
        "  st.markdown(\"- opening_weekend performance\")\n",
        "  st.markdown(\"- number of theatres released\")\n",
        "  st.markdown(\"- production cost\")\n",
        "  st.markdown(\"- domestic gross\")\n",
        "  st.markdown(\"- genre\")\n",
        "\n",
        "  st.markdown(\"**opening weekend performance indicates how much revenue the movie makes by the first weekend of release.\")\n",
        "  st.markdown(\"**number of theatres released indicates how many theatres the movie gets released in, measuring the spread of the movie distribution internationally. If the movie is aired in greater amount of movie theatres, it may have a chance of expanding its audience base, therefore generating a larger return\")\n",
        "  st.markdown(\"**The production cost of each movie indicates the total money spent throughout the production, this may vary based on the different needs of production. \")\n",
        "  st.markdown(\"**Domestic gross indicates the returns generated by the movie within its original nation of release. For instance, the domestic gross of Star Wars EPVII:The Force Awakens measures the total revenue generated in United States. \")\n",
        "  st.markdown(\"**The genre of the movie included: Action,Adventure,Musical,Western,Drama,Thriller/Suspense,Comedy, Horror, Black Comedy,Romantic Comedy\")\n",
        "  st.markdown(\"For movie productions in the future, it is critical to measure from multiple perspectives. \")\n",
        "\n",
        "  st.markdown(\"### Description of Data\")\n",
        "  st.dataframe(df.describe())\n",
        "  st.markdown(\"Descriptions for all quantitative data by:\")\n",
        "\n",
        "  st.markdown(\"Count\")\n",
        "  st.markdown(\"Mean\")\n",
        "  st.markdown(\"Standard Deviation\")\n",
        "  st.markdown(\"Minimum\")\n",
        "  st.markdown(\"Quartiles:25%,50%,70%\")\n",
        "  st.markdown(\"Maximum\")\n",
        "  st.markdown(\"note: The rank and year of release in the description are not relevant quantitative data for observation, one shall ignore the calculations.\")\n",
        "\n",
        "  st.markdown(\"### Missing Values\")\n",
        "  st.markdown(\"Null or NaN values.\")\n",
        "\n",
        "  dfnull = df.isnull().sum()/len(df)*100\n",
        "  totalmiss = dfnull.sum().round(2)\n",
        "  st.write(\"Percentage of total missing values:\",totalmiss)\n",
        "  st.write(dfnull)\n",
        "  if totalmiss == 0.0:\n",
        "    st.success(\"We do not exprience any missing values which is the ideal outcome of our data. We can proceed with higher accuracy in our further prediction.\")\n",
        "  else:\n",
        "    st.warning(\"Poor data quality due to greater than 30 percent of missing value.\")\n",
        "    st.markdown(\" > Theoretically, 25 to 30 percent is the maximum missing values are allowed, there's no hard and fast rule to decide this threshold. It can vary from problem to problem.\")\n",
        "\n",
        "  st.markdown(\"### Completeness\")\n",
        "  st.markdown(\" The ratio of non-missing values to total records in dataset and how comprehensive the data is.\")\n",
        "\n",
        "  st.write(\"Total data length:\", len(df))\n",
        "  nonmissing = (df.notnull().sum().round(2))\n",
        "  completeness= round(sum(nonmissing)/len(df),2)\n",
        "\n",
        "  st.write(\"Completeness ratio:\",completeness)\n",
        "  st.write(nonmissing)\n",
        "  if completeness >= 0.80:\n",
        "    st.success(\"We have completeness ratio greater than 0.85, which is good. It shows that the vast majority of the data is available for us to use and analyze. \")\n",
        "  else:\n",
        "    st.success(\"Poor data quality due to low completeness ratio( less than 0.85).\")\n",
        "\n",
        "elif app_mode == '02 Visualization':\n",
        "  df = pd.read_csv(\"top-500-movies.csv\")\n",
        "  list_variables = df.columns\n",
        "\n",
        "  st.title(\"Visualization\")\n",
        "  symbols = st.multiselect(\"Select two variables\",list_variables,default=['opening_weekend','worldwide_gross'])\n",
        "  width1 = st.sidebar.slider(\"plot width\", 1, 25, 10)\n",
        "  #symbols = st.multiselect(\"\", list_variables, list_variables[:5])\n",
        "  tab1, tab2= st.tabs([\"Line Chart & Bar Chart \",\"📈 Correlation\"])\n",
        "\n",
        "  tab1.subheader(\"Cinematic Success Patterns: A Visual Exploration of Performance Metrics \")\n",
        "  st.line_chart(data=df, x=symbols[0],y=symbols[1], width=0, height=0, use_container_width=True)\n",
        "  st.write(\" \")\n",
        "  st.bar_chart(data=df, x=symbols[0], y=symbols[1], use_container_width=True)\n",
        "\n",
        "  tab2.subheader(\"Correlation Matrix: the Relationships Among Movie Success Variables\")\n",
        "  fig,ax = plt.subplots(figsize=(width1, width1))\n",
        "  sns.heatmap(df.corr(),cmap= sns.cubehelix_palette(8),annot = True, ax=ax)\n",
        "  tab2.write(fig)\n",
        "\n",
        "  st.write(\" \")\n",
        "  st.write(\" \")\n",
        "  st.markdown(\"### Pairplot\")\n",
        "\n",
        "  df2 = df[[list_variables[0],list_variables[1],list_variables[2],list_variables[3],list_variables[4]]]\n",
        "  fig3 = sns.pairplot(df2)\n",
        "  st.pyplot(fig3)\n",
        "\n",
        "\n",
        "elif app_mode == '03 Prediction':\n",
        "    import streamlit as st\n",
        "    import matplotlib.pyplot as plt\n",
        "    import pandas as pd\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "    import numpy as np\n",
        "    import time\n",
        "\n",
        "    # Load data\n",
        "    df = pd.read_csv('top-500-movies.csv')\n",
        "\n",
        "    # Title\n",
        "    st.title(\"Movies Grosses Data Analysis - Prediction\")\n",
        "\n",
        "    # Sidebar selections\n",
        "    prediction_type = st.sidebar.selectbox('Select Type of Prediction', ['Linear Regression'])\n",
        "    list_variables = ['production_cost', 'domestic_gross', 'worldwide_gross', 'opening_weekend', 'theaters']\n",
        "    select_variable = st.sidebar.selectbox('Select Variable to Predict', list_variables)\n",
        "    train_size = st.sidebar.number_input(\"Train Set Size\", min_value=0.00, step=0.01, max_value=1.00, value=0.80)\n",
        "\n",
        "    # Feature selection\n",
        "    output_multi = st.multiselect(\"Select Explanatory Variables\", list_variables, default=['opening_weekend', 'domestic_gross'])\n",
        "\n",
        "    # Splitting data\n",
        "    x = df[output_multi]\n",
        "    y = df[select_variable]\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=train_size)\n",
        "\n",
        "    # Scaling data\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(x_train)\n",
        "    x_train_scaled = scaler.transform(x_train)\n",
        "    x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "    # Linear Regression\n",
        "    if prediction_type == 'Linear Regression':\n",
        "        lr_start_time = time.time()\n",
        "        lr_model = LinearRegression()\n",
        "        lr_model.fit(x_train_scaled, y_train)\n",
        "        lr_pred = lr_model.predict(x_test_scaled)\n",
        "        lr_end_time = time.time()\n",
        "        lr_execution_time = lr_end_time - lr_start_time\n",
        "\n",
        "        # Round up the predicted values to the nearest whole number\n",
        "        lr_pred_rounded = np.ceil(lr_pred)\n",
        "\n",
        "        # Results\n",
        "        st.write(\"Execution time:\", lr_execution_time, \"seconds\")\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "        col1.subheader(\"Feature Columns top 25\")\n",
        "        col1.write(x.head(25))\n",
        "\n",
        "        # Creating a DataFrame for comparing actual and predicted values\n",
        "        y_test_df = pd.DataFrame(y_test).reset_index(drop=True)\n",
        "        predictions_df = pd.DataFrame(lr_pred_rounded, columns=['Predicted_Rounded'])\n",
        "        comparison_df = pd.concat([y_test_df, predictions_df], axis=1)\n",
        "        comparison_df.columns = [select_variable, 'Predicted_Rounded']\n",
        "\n",
        "        st.subheader(\"Comparison of Actual and Predicted Values\")\n",
        "        st.write(comparison_df)\n",
        "\n",
        "    # Plotting Actual vs. Predicted values\n",
        "    rolling_window_size = 50  # The window size can be adjusted to your preference\n",
        "    comparison_df['Actual_Rolling'] = comparison_df[select_variable].rolling(rolling_window_size).mean()\n",
        "    comparison_df['Predicted_Rolling'] = comparison_df['Predicted_Rounded'].rolling(rolling_window_size).mean()\n",
        "\n",
        "    # Plotting smoothed Actual vs. Predicted values as lines\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(comparison_df.index, comparison_df['Actual_Rolling'], label='Actual', color='blue', linestyle='-')\n",
        "    ax.plot(comparison_df.index, comparison_df['Predicted_Rolling'], label='Predicted', color='red', linestyle='-')\n",
        "\n",
        "    # Set the x-axis label, y-axis label, and the title of the graph\n",
        "    ax.set_xlabel('Index')  # Use 'Index' if there is no date or specific x-axis label\n",
        "    ax.set_ylabel(select_variable)  # Use the name of the target variable for the y-axis label\n",
        "    ax.set_title('Comparison of Actual and Predicted Values - Smoothed')  # Title of the graph with indication of smoothing\n",
        "\n",
        "    # Add a legend to distinguish between actual and predicted lines\n",
        "    ax.legend()\n",
        "\n",
        "    # note\n",
        "    st.text(\"Note: '1e8' on the y-axis represents a scale factor of $100,000,000.\")\n",
        "    # Display the plot in Streamlit\n",
        "    ax.set_xlim(right=200)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    # Calculating metrics\n",
        "    mae = mean_absolute_error(y_test, lr_pred_rounded)\n",
        "    r2 = r2_score(y_test, lr_pred_rounded)\n",
        "\n",
        "    # Displaying metrics\n",
        "    st.subheader('Results')\n",
        "    st.write(f\"Mean Absolute Error: {mae}\")\n",
        "    st.write(f\"R^2 Score: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xpEt3gBTsdx",
        "outputId": "51f7582a-2dc8-462b-c6da-442612715a70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[##................] - fetchMetadata: sill resolveWithNewModule yargs-parser@20\u001b[0m\u001b[K\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.148.143.105:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 6.487s\n",
            "your url is: https://wise-drinks-sin.loca.lt\n",
            "2024-03-04 14:09:15.114 Uncaught app exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 535, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 151, in <module>\n",
            "    scaler.fit(x_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\", line 824, in fit\n",
            "    return self.partial_fit(X, y, sample_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\", line 861, in partial_fit\n",
            "    X = self._validate_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 565, in _validate_data\n",
            "    X = check_array(X, input_name=\"X\", **check_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 778, in check_array\n",
            "    dtype_orig = np.result_type(*dtypes_orig)\n",
            "ValueError: at least one array or dtype is required\n",
            "/content/app.py:106: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  sns.heatmap(df.corr(),cmap= sns.cubehelix_palette(8),annot = True, ax=ax)\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}